package multiagent;

import Graph.Node;
import Graph.NodeStatus;
import QLearning.MAction;
import QLearning.WState;
import burlap.mdp.core.state.State;
import burlap.mdp.stochasticgames.JointAction;
import burlap.mdp.stochasticgames.model.JointRewardFunction;

public class Reward implements JointRewardFunction {

	@Override
	public double[] reward(State s, JointAction a, State sp) {

		MAction dfaction = (MAction) a.action(0);
		String dname = dfaction.getNodeName();
		String daction = dfaction.getAction();

		MAction ataction = (MAction) a.action(1);
		String aname = ataction.getNodeName();
		String aaction = ataction.getAction();

		State w = s.copy();
		WState state = (WState) w;
		int size = state.getNodeList().size();

		State wp = sp.copy();
		WState statep = (WState) wp;
		int sizep = statep.getNodeList().size();

		int dindex = 0;
		int aindex = 0;

		// Find the index of the node in the graph on which action is
		// performed.
		for (int i = 0; i < size; i++) {
			if (dname.equals(state.getNodeList().get(i).getName())) {
				dindex = i;
				break;
			}
		}
		for (int i = 0; i < sizep; i++) {
			if (aname.equals(state.getNodeList().get(i).getName())) {
				aindex = i;
				break;
			}
		}
		
		if (dindex == aindex) {
			WorldForMultiAgent.isDefenderAttackerAccessingSameNode = true;

		} else {
			
		}

		return null;
	}

}
