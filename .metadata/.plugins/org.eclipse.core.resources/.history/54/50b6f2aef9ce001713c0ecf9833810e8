package multiagent;

import java.util.ArrayList;

import Graph.Node;
import Graph.NodeStatus;
import QLearning.MAction;
import QLearning.MainClass;
import QLearning.WState;
import burlap.mdp.core.state.State;
import burlap.mdp.stochasticgames.JointAction;
import burlap.mdp.stochasticgames.model.JointRewardFunction;

public class Reward implements JointRewardFunction {

	@Override
	public double[] reward(State s, JointAction a, State sp) {

		double[] result = new double[2];

		MAction dfaction = (MAction) a.action(0);
		String dname = dfaction.getNodeName();
		String daction = dfaction.getAction();

		MAction ataction = (MAction) a.action(1);
		String aname = ataction.getNodeName();
		String aaction = ataction.getAction();

		State w = s.copy();
		WState state = (WState) w;
		int size = state.getNodeList().size();

		State wp = sp.copy();
		WState statep = (WState) wp;
		int sizep = statep.getNodeList().size();

		int dindex = 0;
		int aindex = 0;

		// Find the index of the node in the graph on which action is
		// performed.
		for (int i = 0; i < size; i++) {
			if (dname.equals(state.getNodeList().get(i).getName())) {
				dindex = i;
				break;
			}
		}
		for (int i = 0; i < sizep; i++) {
			if (aname.equals(state.getNodeList().get(i).getName())) {
				aindex = i;
				break;
			}
		}

		// The index of nodes which agents performed actions will remain same
		// in both the state that is state and statep. Therefore, there is no
		// need of creating and finding them separately.

		Node dn = state.getNodeList().get(dindex);
		Node an = state.getNodeList().get(aindex);
		Node dnp = statep.getNodeList().get(dindex);
		Node anp = statep.getNodeList().get(aindex);
		result[0] = getRewardForDefender(daction, dn, dnp, aaction, an, anp);
		result[1] = getRewardForAttacker(daction, dn, dnp, aaction, an, anp);

		return result;
	}

	public double getRewardForDefender(String defenderaction, Node dn,
			Node dnp, String attackerAction, Node an, Node anp) {

		if (WorldForMultiAgent.defenderNode != null
				&& WorldForMultiAgent.defenderNode
						.equals(WorldForMultiAgent.attackerNode))
			return 1000;

		// Action is SCAN
		if (defenderaction.equals(MainClass.ACTION_SCAN)) {

			if (anp.getName().equals("N6")
					&& anp.getAstatus().equals(NodeStatus.HACKED))
				return -1000;

			if (dnp.getDstatus().equals(NodeStatus.HACKED))
				return MainClass.reward.get(dnp.getName()) * 2;

			if ((dn.getDstatus().equals(NodeStatus.UNKNOWN) || dn.getDstatus()
					.equals(NodeStatus.PATCHED))
					&& dnp.getDstatus().equals(NodeStatus.VULNERABLE))
				return MainClass.reward.get(dnp.getName());

			// When dnp is either UNKNOWN or PATCHED, there is no advantage of
			// scanning that function. return 0 in the end.

		} else {
			// Action is PATCH

			if ((dn.getDstatus().equals(NodeStatus.VULNERABLE) || dn
					.getDstatus().equals(NodeStatus.HACKED))
					&& dnp.getDstatus().equals(NodeStatus.PATCHED))
				return MainClass.reward.get(dnp.getName()) * 4;

			// When dn status is PATCHED or UNKNOWN, agent receive 0 reward.
			if (dn.getDstatus().equals(NodeStatus.PATCHED)
					|| dn.getDstatus().equals(NodeStatus.UNKNOWN))
				return 0;
		}
		return 0;
	}

	public double getRewardForAttacker(String defenderaction, Node dn,
			Node dnp, String attackerAction, Node an, Node anp) {

		if (isTerminal(anp) && WorldForMultiAgent.isDefWin)
			return -500;

		if (isTerminal(anp) && !WorldForMultiAgent.isDefWin)
			return 500;

		// Action is SCAN
		if (attackerAction.equals(MainClass.ACTION_SCAN)) {

			if (an.getAstatus().equals(NodeStatus.UNKNOWN)
					&& anp.getAstatus().equals(NodeStatus.VULNERABLE))
				return MainClass.reward.get(dnp.getName()) * 2;

			if (an.getAstatus().equals(NodeStatus.PATCHED)
					&& anp.getAstatus().equals(NodeStatus.VULNERABLE))
				return MainClass.reward.get(dnp.getName()) * 2;

			if (an.getAstatus().equals(NodeStatus.VULNERABLE)
					&& anp.getAstatus().equals(NodeStatus.VULNERABLE))
				return 0;

			// Action is HACK
		} else {

			if ((an.getAstatus().equals(NodeStatus.VULNERABLE))
					&& anp.getAstatus().equals(NodeStatus.HACKED)
					&& anp.getName().equals("N6"))
				return 1000;

			if ((an.getAstatus().equals(NodeStatus.VULNERABLE))
					&& anp.getAstatus().equals(NodeStatus.HACKED))
				return MainClass.reward.get(dnp.getName()) * 3;

		}
		return 0;
	}

	// Terminal Function for deciding early rewards.
	public boolean isTerminal(Node n) {

		// When defender is trying to access a node on which attacker is
		// present.
		if (WorldForMultiAgent.defenderNode != null
				&& WorldForMultiAgent.defenderNode
						.equals(WorldForMultiAgent.attackerNode)) {
			WorldForMultiAgent.isDefWin = true;
			return true;
		}

		// When last node in the system gets HACKED by the attacker. Now
		// attacked can control the system functionality.
		if (n.getName().equals("N6")) {
			if (n.getStatus().equals(NodeStatus.HACKED)) {
				WorldForMultiAgent.isDefWin = false;
				return true;
			}
		}

		return false;
	}
}
