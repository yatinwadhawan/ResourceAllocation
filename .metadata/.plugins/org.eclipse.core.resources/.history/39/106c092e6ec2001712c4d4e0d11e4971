package multiagent;

import java.util.List;
import burlap.mdp.auxiliary.DomainGenerator;
import burlap.mdp.core.Domain;
import burlap.mdp.core.StateTransitionProb;
import burlap.mdp.core.TerminalFunction;
import burlap.mdp.core.action.Action;
import burlap.mdp.core.action.UniversalActionType;
import burlap.mdp.core.state.State;
import burlap.mdp.singleagent.SADomain;
import burlap.mdp.singleagent.model.FactoredModel;
import burlap.mdp.singleagent.model.RewardFunction;
import burlap.mdp.stochasticgames.JointAction;
import burlap.mdp.stochasticgames.model.FullJointModel;
import burlap.mdp.stochasticgames.model.JointRewardFunction;
import burlap.mdp.stochasticgames.world.World;

public class WorldForMultiAgent {

	public void generateDomain() {

		SADomain domain = new SADomain();
		// Add Actions

		StateWorld statemodel = new StateWorld();
		Reward rf = new Reward();
		Terminal tf = new Terminal();

		World w = new World(domain, rf, tf, initialState);
	}

}
