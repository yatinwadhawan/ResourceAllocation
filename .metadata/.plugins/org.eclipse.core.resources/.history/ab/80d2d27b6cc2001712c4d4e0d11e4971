package multiagent;

import java.util.List;
import burlap.mdp.auxiliary.DomainGenerator;
import burlap.mdp.core.Domain;
import burlap.mdp.core.StateTransitionProb;
import burlap.mdp.core.TerminalFunction;
import burlap.mdp.core.action.Action;
import burlap.mdp.core.action.UniversalActionType;
import burlap.mdp.core.state.State;
import burlap.mdp.singleagent.SADomain;
import burlap.mdp.singleagent.model.FactoredModel;
import burlap.mdp.singleagent.model.RewardFunction;
import burlap.mdp.stochasticgames.JointAction;
import burlap.mdp.stochasticgames.model.FullJointModel;
import burlap.mdp.stochasticgames.model.JointRewardFunction;

public class WorldForMultiAgent implements DomainGenerator {

	@Override
	public Domain generateDomain() {

		SADomain domain = new SADomain();

		// Add Actions
		// for (int i = 0; i < MainClass.ls.size(); i++) {
		// domain.addActionType(new UniversalActionType(MainClass.ls.get(i)));
		// }

		StateWorld smodel = new StateWorld();
		Reward rf = new Reward();
		Terminal tf = new Terminal();

		domain.setModel(smodel);

		return domain;
	}

	protected class StateWorld implements FullJointModel {

		@Override
		public State sample(State s, JointAction a) {
			// TODO Auto-generated method stub
			return null;
		}

		@Override
		public List<StateTransitionProb> stateTransitions(State s, JointAction a) {
			// TODO Auto-generated method stub
			return null;
		}

	}

	protected class Reward implements JointRewardFunction {

		@Override
		public double[] reward(State s, JointAction a, State sp) {
			// TODO Auto-generated method stub
			return null;
		}

	}

	protected class Terminal implements TerminalFunction {

		@Override
		public boolean isTerminal(State s) {
			// TODO Auto-generated method stub
			return false;
		}

	}

}
