package multiagent;

import java.util.List;
import burlap.mdp.auxiliary.DomainGenerator;
import burlap.mdp.core.Domain;
import burlap.mdp.core.StateTransitionProb;
import burlap.mdp.core.TerminalFunction;
import burlap.mdp.core.action.Action;
import burlap.mdp.core.action.UniversalActionType;
import burlap.mdp.core.state.State;
import burlap.mdp.singleagent.SADomain;
import burlap.mdp.singleagent.model.FactoredModel;
import burlap.mdp.singleagent.model.RewardFunction;
import burlap.mdp.stochasticgames.JointAction;
import burlap.mdp.stochasticgames.model.FullJointModel;
import burlap.mdp.stochasticgames.model.JointRewardFunction;

public class WorldForMultiAgent {

	public void generateDomain() {

		SADomain domain = new SADomain();

		// Add Actions
		// for (int i = 0; i < MainClass.ls.size(); i++) {
		// domain.addActionType(new UniversalActionType(MainClass.ls.get(i)));
		// }

		StateWorld smodel = new StateWorld();
		Reward rf = new Reward();
		TerminalState tf = new TerminalState();

	}

}
